{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 627,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01594896331738437,
      "grad_norm": 0.6118358373641968,
      "learning_rate": 4.920255183413078e-05,
      "loss": 4.6062,
      "step": 10
    },
    {
      "epoch": 0.03189792663476874,
      "grad_norm": 0.38495898246765137,
      "learning_rate": 4.8405103668261565e-05,
      "loss": 4.3093,
      "step": 20
    },
    {
      "epoch": 0.04784688995215311,
      "grad_norm": 0.5604434609413147,
      "learning_rate": 4.760765550239234e-05,
      "loss": 4.3865,
      "step": 30
    },
    {
      "epoch": 0.06379585326953748,
      "grad_norm": 0.7435421943664551,
      "learning_rate": 4.681020733652313e-05,
      "loss": 4.5136,
      "step": 40
    },
    {
      "epoch": 0.07974481658692185,
      "grad_norm": 0.6294821500778198,
      "learning_rate": 4.6012759170653905e-05,
      "loss": 4.0337,
      "step": 50
    },
    {
      "epoch": 0.09569377990430622,
      "grad_norm": 0.784232497215271,
      "learning_rate": 4.521531100478469e-05,
      "loss": 4.429,
      "step": 60
    },
    {
      "epoch": 0.11164274322169059,
      "grad_norm": 0.9275608658790588,
      "learning_rate": 4.4417862838915475e-05,
      "loss": 4.4244,
      "step": 70
    },
    {
      "epoch": 0.12759170653907495,
      "grad_norm": 0.4857812225818634,
      "learning_rate": 4.362041467304626e-05,
      "loss": 4.3528,
      "step": 80
    },
    {
      "epoch": 0.14354066985645933,
      "grad_norm": 0.9451141953468323,
      "learning_rate": 4.282296650717704e-05,
      "loss": 4.1364,
      "step": 90
    },
    {
      "epoch": 0.1594896331738437,
      "grad_norm": 1.0974304676055908,
      "learning_rate": 4.2025518341307815e-05,
      "loss": 4.3621,
      "step": 100
    },
    {
      "epoch": 0.17543859649122806,
      "grad_norm": 1.8900423049926758,
      "learning_rate": 4.12280701754386e-05,
      "loss": 4.358,
      "step": 110
    },
    {
      "epoch": 0.19138755980861244,
      "grad_norm": 0.7232918739318848,
      "learning_rate": 4.043062200956938e-05,
      "loss": 4.0076,
      "step": 120
    },
    {
      "epoch": 0.20733652312599682,
      "grad_norm": 1.040949821472168,
      "learning_rate": 3.963317384370016e-05,
      "loss": 4.2814,
      "step": 130
    },
    {
      "epoch": 0.22328548644338117,
      "grad_norm": 0.7012400031089783,
      "learning_rate": 3.883572567783094e-05,
      "loss": 3.9989,
      "step": 140
    },
    {
      "epoch": 0.23923444976076555,
      "grad_norm": 1.022481918334961,
      "learning_rate": 3.8038277511961725e-05,
      "loss": 3.9207,
      "step": 150
    },
    {
      "epoch": 0.2551834130781499,
      "grad_norm": 0.7630135416984558,
      "learning_rate": 3.72408293460925e-05,
      "loss": 4.1861,
      "step": 160
    },
    {
      "epoch": 0.2711323763955343,
      "grad_norm": 0.975555419921875,
      "learning_rate": 3.644338118022329e-05,
      "loss": 3.7922,
      "step": 170
    },
    {
      "epoch": 0.28708133971291866,
      "grad_norm": 0.8771224021911621,
      "learning_rate": 3.5645933014354065e-05,
      "loss": 4.0707,
      "step": 180
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 1.5456188917160034,
      "learning_rate": 3.484848484848485e-05,
      "loss": 3.77,
      "step": 190
    },
    {
      "epoch": 0.3189792663476874,
      "grad_norm": 1.2998796701431274,
      "learning_rate": 3.4051036682615634e-05,
      "loss": 3.8495,
      "step": 200
    },
    {
      "epoch": 0.3349282296650718,
      "grad_norm": 1.5140702724456787,
      "learning_rate": 3.325358851674641e-05,
      "loss": 3.6556,
      "step": 210
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 1.463457703590393,
      "learning_rate": 3.24561403508772e-05,
      "loss": 3.639,
      "step": 220
    },
    {
      "epoch": 0.3668261562998405,
      "grad_norm": 0.9208349585533142,
      "learning_rate": 3.1658692185007975e-05,
      "loss": 3.819,
      "step": 230
    },
    {
      "epoch": 0.3827751196172249,
      "grad_norm": 0.9625469446182251,
      "learning_rate": 3.086124401913876e-05,
      "loss": 3.8767,
      "step": 240
    },
    {
      "epoch": 0.39872408293460926,
      "grad_norm": 1.3233989477157593,
      "learning_rate": 3.0063795853269537e-05,
      "loss": 3.7837,
      "step": 250
    },
    {
      "epoch": 0.41467304625199364,
      "grad_norm": 1.4244664907455444,
      "learning_rate": 2.9266347687400318e-05,
      "loss": 3.4634,
      "step": 260
    },
    {
      "epoch": 0.430622009569378,
      "grad_norm": 1.1812535524368286,
      "learning_rate": 2.84688995215311e-05,
      "loss": 3.5155,
      "step": 270
    },
    {
      "epoch": 0.44657097288676234,
      "grad_norm": 0.996329665184021,
      "learning_rate": 2.767145135566188e-05,
      "loss": 3.6343,
      "step": 280
    },
    {
      "epoch": 0.4625199362041467,
      "grad_norm": 1.5304057598114014,
      "learning_rate": 2.6874003189792662e-05,
      "loss": 3.613,
      "step": 290
    },
    {
      "epoch": 0.4784688995215311,
      "grad_norm": 1.3167041540145874,
      "learning_rate": 2.6076555023923443e-05,
      "loss": 3.4446,
      "step": 300
    },
    {
      "epoch": 0.4944178628389155,
      "grad_norm": 1.250635027885437,
      "learning_rate": 2.527910685805423e-05,
      "loss": 3.3402,
      "step": 310
    },
    {
      "epoch": 0.5103668261562998,
      "grad_norm": 1.864622950553894,
      "learning_rate": 2.448165869218501e-05,
      "loss": 3.5948,
      "step": 320
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 1.0928716659545898,
      "learning_rate": 2.368421052631579e-05,
      "loss": 3.3836,
      "step": 330
    },
    {
      "epoch": 0.5422647527910686,
      "grad_norm": 2.33951473236084,
      "learning_rate": 2.288676236044657e-05,
      "loss": 3.4175,
      "step": 340
    },
    {
      "epoch": 0.5582137161084529,
      "grad_norm": 1.1828980445861816,
      "learning_rate": 2.2089314194577353e-05,
      "loss": 3.5723,
      "step": 350
    },
    {
      "epoch": 0.5741626794258373,
      "grad_norm": 1.4486830234527588,
      "learning_rate": 2.1291866028708134e-05,
      "loss": 3.5493,
      "step": 360
    },
    {
      "epoch": 0.5901116427432217,
      "grad_norm": 1.732999324798584,
      "learning_rate": 2.0494417862838915e-05,
      "loss": 3.724,
      "step": 370
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 1.0104773044586182,
      "learning_rate": 1.9696969696969697e-05,
      "loss": 3.5552,
      "step": 380
    },
    {
      "epoch": 0.6220095693779905,
      "grad_norm": 2.0366787910461426,
      "learning_rate": 1.8899521531100478e-05,
      "loss": 3.5956,
      "step": 390
    },
    {
      "epoch": 0.6379585326953748,
      "grad_norm": 1.4386156797409058,
      "learning_rate": 1.8102073365231263e-05,
      "loss": 3.4534,
      "step": 400
    },
    {
      "epoch": 0.6539074960127592,
      "grad_norm": 1.3828070163726807,
      "learning_rate": 1.7304625199362044e-05,
      "loss": 3.4047,
      "step": 410
    },
    {
      "epoch": 0.6698564593301436,
      "grad_norm": 1.8928899765014648,
      "learning_rate": 1.6507177033492825e-05,
      "loss": 3.6393,
      "step": 420
    },
    {
      "epoch": 0.6858054226475279,
      "grad_norm": 1.1452146768569946,
      "learning_rate": 1.5709728867623606e-05,
      "loss": 3.6079,
      "step": 430
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 1.4964349269866943,
      "learning_rate": 1.4912280701754386e-05,
      "loss": 3.67,
      "step": 440
    },
    {
      "epoch": 0.7177033492822966,
      "grad_norm": 1.83797025680542,
      "learning_rate": 1.4114832535885167e-05,
      "loss": 3.5708,
      "step": 450
    },
    {
      "epoch": 0.733652312599681,
      "grad_norm": 1.549747347831726,
      "learning_rate": 1.331738437001595e-05,
      "loss": 3.6385,
      "step": 460
    },
    {
      "epoch": 0.7496012759170654,
      "grad_norm": 1.8554681539535522,
      "learning_rate": 1.2519936204146731e-05,
      "loss": 3.5869,
      "step": 470
    },
    {
      "epoch": 0.7655502392344498,
      "grad_norm": 1.392438530921936,
      "learning_rate": 1.1722488038277513e-05,
      "loss": 3.7498,
      "step": 480
    },
    {
      "epoch": 0.7814992025518341,
      "grad_norm": 1.163395881652832,
      "learning_rate": 1.0925039872408294e-05,
      "loss": 3.6037,
      "step": 490
    },
    {
      "epoch": 0.7974481658692185,
      "grad_norm": 1.2294368743896484,
      "learning_rate": 1.0127591706539077e-05,
      "loss": 3.4807,
      "step": 500
    },
    {
      "epoch": 0.8133971291866029,
      "grad_norm": 2.0509350299835205,
      "learning_rate": 9.330143540669856e-06,
      "loss": 3.1947,
      "step": 510
    },
    {
      "epoch": 0.8293460925039873,
      "grad_norm": 1.2507504224777222,
      "learning_rate": 8.532695374800638e-06,
      "loss": 3.6384,
      "step": 520
    },
    {
      "epoch": 0.8452950558213717,
      "grad_norm": 1.521118402481079,
      "learning_rate": 7.73524720893142e-06,
      "loss": 3.3549,
      "step": 530
    },
    {
      "epoch": 0.861244019138756,
      "grad_norm": 1.0099776983261108,
      "learning_rate": 6.937799043062202e-06,
      "loss": 3.4134,
      "step": 540
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 1.6502711772918701,
      "learning_rate": 6.140350877192982e-06,
      "loss": 3.4551,
      "step": 550
    },
    {
      "epoch": 0.8931419457735247,
      "grad_norm": 1.4328489303588867,
      "learning_rate": 5.342902711323764e-06,
      "loss": 3.5152,
      "step": 560
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.976984441280365,
      "learning_rate": 4.5454545454545455e-06,
      "loss": 3.4914,
      "step": 570
    },
    {
      "epoch": 0.9250398724082934,
      "grad_norm": 1.4276126623153687,
      "learning_rate": 3.7480063795853268e-06,
      "loss": 3.5393,
      "step": 580
    },
    {
      "epoch": 0.9409888357256778,
      "grad_norm": 1.6916983127593994,
      "learning_rate": 2.9505582137161084e-06,
      "loss": 3.503,
      "step": 590
    },
    {
      "epoch": 0.9569377990430622,
      "grad_norm": 1.6744221448898315,
      "learning_rate": 2.15311004784689e-06,
      "loss": 3.2705,
      "step": 600
    },
    {
      "epoch": 0.9728867623604466,
      "grad_norm": 1.3848187923431396,
      "learning_rate": 1.3556618819776716e-06,
      "loss": 3.3542,
      "step": 610
    },
    {
      "epoch": 0.988835725677831,
      "grad_norm": 0.9481411576271057,
      "learning_rate": 5.582137161084529e-07,
      "loss": 3.5509,
      "step": 620
    }
  ],
  "logging_steps": 10,
  "max_steps": 627,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 90118272540672.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
